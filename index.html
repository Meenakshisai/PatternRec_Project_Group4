<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ğŸ‡ Blackberry & Lime Classifier</title>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      background-color: #fefefe;
      color: #2c2c2c;
      padding: 2rem;
      line-height: 1.7;
    }
    h1, h2, h3 {
      font-weight: 700;
    }
    h1 {
      color: #ff1493; 
    }
    h2 {
      color: #4169e1; 
    }
    h3 {
      color: #2e8b57; 
    }
    a {
      color: #d2691e;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    pre {
      background-color: #f4f4f4;
      padding: 1rem;
      border-radius: 5px;
      overflow-x: auto;
    }
    ul {
      margin-left: 2rem;
    }
    img {
      max-width: 100%;
      margin: 1rem 0;
      border-radius: 8px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
  </style>
</head>
<body>

  <h1>ğŸ‡ CSE 455/555 Term Project Report</h1>
  <h2>ğŸ§  Visual Classification of Blackberry and Lime using Transfer Learning</h2>
  <p><strong>Team Role:</strong> CV Engineer â€“ Meenakshi Gundluri</p>

  <h2>ğŸ“Œ 1. Introduction</h2>
  <p>This project focuses on visually identifying fruitsâ€”specifically blackberries and limesâ€”and classifying them further by their presentation. Using deep learning and transfer learning, we build a smart classifier and deploy it for interactive use.</p>

  <h2>ğŸ—ƒï¸ 2. Dataset Preparation</h2>
  <h3>ğŸ“· 2.1 Image Collection</h3>
  <p>Images were captured manually to simulate real-world variations. They included cluttered backgrounds, natural light, and multiple contexts to ensure model robustness.</p>

  <h3>ğŸŒ€ 2.2 Data Variations</h3>
  <ul>
    <li>Halved</li>
    <li>In Context</li>
    <li>In a Container</li>
    <li>Single Berry</li>
    <li>Small Group</li>
    <li>Whole</li>
  </ul>

  <h3>ğŸ—‚ï¸ 2.3 Folder Structure & Renaming</h3>
  <p>Images were renamed uniformly and sorted into train/val/test sets with an approximate 70:20:10 split. This was automated to ensure reproducibility.</p>

  <h2>ğŸ› ï¸ 3. Model Development</h2>
  <h3>ğŸ’» 3.1 Tools</h3>
  <ul>
    <li>Python, PyTorch, Torchvision</li>
    <li>VS Code Jupyter Notebooks</li>
    <li>Gradio & Hugging Face Spaces</li>
  </ul>

  <h3>âš™ï¸ 3.2 Architecture</h3>
  <p>We fine-tuned a ResNet-18 pre-trained model. The final fully-connected layer was replaced to output either 2 or 6 classes based on the classification task.</p>

  <h3>ğŸ¯ 3.3 Training Parameters</h3>
  <p><strong>Loss:</strong> CrossEntropyLoss <br>
     <strong>Optimizer:</strong> Adam <br>
     <strong>Epochs:</strong> 5</p>

  <h2>ğŸ“ˆ 4. Evaluation Results</h2>
  <h3>ğŸ‹ 4.1 Produce Classifier</h3>
  <pre><code>
              precision    recall  f1-score   support
  blackberry       1.00      1.00      1.00       450
        lime       1.00      1.00      1.00       451
     accuracy                           1.00       901
    macro avg       1.00      1.00      1.00       901
 weighted avg       1.00      1.00      1.00       901
  </code></pre>

  <h4>ğŸ§¾ Confusion Matrix:</h4>
  <a href="https://github.com/Meenakshisai/PatternRec_Project_Group4/blob/main/produce_confussion_matrix.png?raw=true" target="_blank">
    <img src="https://github.com/Meenakshisai/PatternRec_Project_Group4/blob/main/produce_confussion_matrix.png?raw=true" alt="Produce Confusion Matrix"/>
  </a>

  <h3>ğŸ§º 4.2 Variation Classifier</h3>
  <pre><code>
                precision    recall  f1-score   support
        Halved       0.99      0.99      0.99       151
    In Context       0.99      0.99      0.99       150
In a Container       1.00      1.00      1.00       150
  Single Berry       0.99      1.00      1.00       150
   Small Group       1.00      0.99      1.00       150
         Whole       0.99      1.00      0.99       150
     accuracy                           0.99       901
    macro avg       0.99      0.99      0.99       901
 weighted avg       0.99      0.99      0.99       901
  </code></pre>

  <h4>ğŸ§¾ Confusion Matrix:</h4>
  <a href="https://github.com/Meenakshisai/PatternRec_Project_Group4/blob/main/variation_confussion_matrix.png?raw=true" target="_blank">
    <img src="https://github.com/Meenakshisai/PatternRec_Project_Group4/blob/main/variation_confussion_matrix.png?raw=true" alt="Variation Confusion Matrix"/>
  </a>

  <h2>ğŸš€ 5. Web App Deployment</h2>
  <p>Using <strong>Gradio</strong>, we developed a simple web app where users can upload an image and get both produce and variation predictions.</p>

  <p>ğŸ”— <strong>Live Demo:</strong> <a href="https://huggingface.co/spaces/brs13/blackberry-lime-classifier" target="_blank">Hugging Face Space</a></p>
  <p>ğŸ’» <strong>Source Code:</strong> <a href="https://github.com/Meenakshisai/PatternRec_Project_Group4.git" target="_blank">GitHub Repository</a></p>

  <h2>ğŸ§¾ 6. Conclusion</h2>
  <p>This project successfully demonstrated a two-stage image classification system with strong performance. The application is robust, scalable, and has real-world potential in grocery tech, farming, and inventory automation.</p>

  <h2>ğŸ§  7. Future Enhancements</h2>
  <ul>
    <li>Expand dataset with more fruits ğŸ“</li>
    <li>Add Grad-CAM for model explainability ğŸ“Š</li>
    <li>Enable real-time camera stream integration ğŸ“·</li>
    <li>Experiment with MobileNet for edge devices ğŸ“±</li>
  </ul>

  <h2>ğŸ™ 8. Acknowledgements</h2>
  <p>Thanks to CSE 455/555 course instructors and peers at the University at Buffalo for providing continuous support and guidance through this enriching journey!</p>

</body>
</html>
